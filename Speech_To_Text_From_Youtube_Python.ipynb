{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jTec1Q7act",
        "outputId": "97a020e9-c8ca-4043-81f6-dd821623732b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy==1.0.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytubefix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P8kbiJN8_u2",
        "outputId": "df4694aa-70cc-4d20-ea6c-0ed4197e9f57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytubefix\n",
            "  Downloading pytubefix-8.12.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Downloading pytubefix-8.12.1-py3-none-any.whl (730 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/730.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m727.0/730.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.7/730.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytubefix\n",
            "Successfully installed pytubefix-8.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQj_j2YC9Ycc",
        "outputId": "a627c021-1660-4694-eac9-4348924d8e9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803374 sha256=708b378b430495282aa55dab0f1eba5f0d3363dbace45c1254bbd21916635a9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "from moviepy.editor import *\n",
        "import whisper"
      ],
      "metadata": {
        "id": "TFiX5jJ98PIV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL del video de YouTube\n",
        "url = \"https://www.youtube.com/watch?v=gfuQthzZM78\""
      ],
      "metadata": {
        "id": "9NVEnojE8W6Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer el modelo que se va a usar\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKa9cK6E9-nB",
        "outputId": "2840523d-5e49-49fb-ff1a-3394ac2f1a74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:04<00:00, 29.2MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar el video usando pytube\n",
        "yt = YouTube(url)\n",
        "video_stream = yt.streams.filter(only_video=False, file_extension=\"mp4\").first()\n",
        "video_path = video_stream.download(filename=\"video.mp4\")"
      ],
      "metadata": {
        "id": "JTdT1LRo8sDt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer el audio usando moviepy\n",
        "video = VideoFileClip(video_path)\n",
        "audio_path = \"audio.mp3\"\n",
        "video.audio.write_audiofile(audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQTKsDtw9Me7",
        "outputId": "09bea7ae-b9b3-4a0f-b1cf-6c05957b6a24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribir audio\n",
        "result = model.transcribe(audio_path)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3De61ww-EzA",
        "outputId": "25df9300-339e-4051-86b5-111a9dfcfc7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Y los próximos dos años lo que haremos tener modelos de inteligencia artificial, más inteligentes que cualquier humano en cualquier disciplina. Esto, junto a la incapacidad actual de nuestros países de construir AI, pondrá nuestras naciones en la posición económica y de seguridad nacional, terrible, a la que haremos despertar yo mismo. Esto nos en la potencia que AI va a destruirnos, no. Un humano sigue siendo quien decida con su propia agencia y voluntad que hacía. Por ahora, pero si racional creer que esto no cambiará, todas las economías del mundo y el estatus CUA actual del poder. La matemática detrás de la inteligencia artificial no es difícil. Es algero lineal, cálculo vetorial, estructuras de datos, cosas que existen hace 50 años. Hay métodos novedosos como los espacios multidimensionales o enevectoriales donde se agregan las palabras o el modelo del transformador y la atención. Estas palabras, aunque suenen inaccesibles, se pueden enseñar en cualquier escuela o universidad que enseña conceptos básicos de ingeniería, está al alcance de todos nuestros países. La infraestructurano o es prácticamente imposible para países en vías de desarrollo como los de América Latina, tener los centros de datos necesarios para entrenar los modelos que están en la frontera. Yo hablaba con muchas personas de gobierno y la realidad es que los gobernantes, funcionarios, ministros y secretarios de con nuestros países no entienden esto, pero es verdad. Si hoy en día, un nuestros países quisiera entrenar modelos como los de OpenAI o incluso los de DeepSec, no podría, no desde cero. Creemos, incorrectamente, que porque Amazon y Microsoft vienen a instalar data centros en nuestros países podemos competir. Esto no es verdad. Y esta creencia nace de que no entendemos los fundamentos de cómo funciona, cómo negocio y cómo industria la inteligencia artificial. Y los datos centros no es lo único fuera nuestro alcance hoy. La inteligencia artificial en esencia, parte de la existencia de unos microchips muy avanzados, hechos de transistores y la distancia entre transistor y transistor es de 21 átomos de silicio. La tecnología usada para construir estos chips se llama Lázers Extremos Ultravioleta, olitografía extrema ultravioleta y solo existe en Holanda. La empresa landesa a SML es la única capaz de construir esta máquina. No la tiene Estados Unidos, China, Japón, ni ningún otro lugar logra ese nivel de tecnología. Y si en esa máquina no hay inteligencia artificial. La única empresa capaz de colocar estas máquinas en una línea de producción en fábricas, es TSMC en Taiwan. Al final del gobierno Biden, Estados Unidos logró tener una planta de TSMC en Arizona que fabrica una versión anterior de la más avanzada de estos chips, pero la más avanzada sigue siendo Taiwan. China, aunque, compite mucho y corre rápido a un está a años de distancia de esto. El resto del mundo mucho más lejos. Los microchips se fabrican a partir de transformar arena en cristales de silicio y perpuros. Solo Japón, Alemania, Estados Unidos, Taiwan y Corea del Sur son capaces de fabricar ese cristal. México, Colombia, Argentina, Brasil y Chile tienen las compañías capaces de hacer ese cristal si así lo decidieron. Algunas compañías con los componentes cercanos para lograrlo son, por ejemplo, corona o tecnoglas en Colombia. Pero en día, no somos parte significativa de toda esa caena de distribución. Luego es el diseño de los chips. Solo muy pocas compañías en Japón, Estados Unidos, Inglaterra y China son capaces de diseñar el chip. Con un chip diseñado, las máquinas olandeses de ASML en las líneas de producción de TES en CYENTAIWAN logran fabricarlo. En VIRIA es la más famosa de esas compañías de diseño. Y la inteligencia artificial no ocurre solo con estos chips, es posible a través de miles de estos chips en datacenters masivos. Estos chips hoy son tan importantes que su tecnología exportación es protegida y controlada por las mismas leyes que controlan la proliferación de armas nucleares. Esto no es una exageración. La tecnología detrás de los misiles valísticos intercontinentales y otras tecnologías de guerra. El chip HCN de Midia, por ejemplo, es el que usan compañías como OpenAI para entrenar sus modelos más avanzados. Ningún país o empresa extranjera es capaz de comprar chips HCN en un volumen significativo para competir con OpenAI. Se necesita un permiso previo del gobierno de Estados Unidos y una negociación con las compañías que es prácticamente imposible ganar. China entreno DeepSick en un datacenter de más o menos 2.080 chips H800 que son la versión anterior a la H100. Y fueron comprados antes de que Estados Unidos impusiera las restricciones de exportación de tecnología microchips a China y eventualmente al mundo. La inteligencia artificial ya es parte de todos los empleos que usan razón. Todos los empleos que usan una computadora usan AI. De frente o escondidas. Y sí, principalmente para resumir lo que no quiero leer y para redactar lo que no quieres escribir. Pero vamos allá. Todos los equipos de clase mundial creando software. Estamos usando AI para programar más rápido. Algunos ingenieros sobre todos los más senior. Siguiendo la excusa de que el código no es perfecto. Pero eso no excusa. Código imperfecto, escrito eitrado alta velocidad es mejor que código perfecto hecho lentamente de forma artesanal. Y no es un punto estático. AI cada día es mejor programando haciendo código razonando. La inteligencia artificial sigue creciendo en su capacidad de razonar, escribir software y entender. Esto va a crear una nueva generación de compañías que con muy poquitos empleados lo van a construir productos millonarios apoyándose de AI. Y lo mismo le pasará a todos los empleos que necesiten razonamiento y lógica. Los estrocamos muy rápido del punto en el que todas las compañías van a necesitar usar AI para complementar el talento humano que les permite tomar decisiones más rápidas en logística, en operaciones y en decisiones de negocio. O van a ser destruidas. Por compañías AI first. Esto ya ha pasado antes. Brasil solía ser una economía de exportación de todo tipo de productos de valor agregado. Lentamente por no innovar han ido perdiendo esa ventaja y volvieron a hacer un país que principalmente exporta materias primas. Eventualmente, todas las decisiones mayores de gobierno van a incluir en la cadena de decisión el uso de inteligencia artificial. Sin duda, hoy en día, todos los empleados de gobierno y todas las personas detrás de una computadora trabajando en un gobierno han pasado algo de sus decisiones y sus documentos oficiales. Por ahí. Todas es imposible prohibirlo. Prohibirlo solo hace que lo usan en secreto. El problema es que todo uso de AI es transparente para los dueños del datacenter y del modelo de inteligencia artificial. Por la naturaleza matemática como funciona la inteligencia artificial, esta información no se puede encryptar. No es si frabe. Imagina una decisión de negociación que tienes que mantener secreto corporativo. Pero tu proceso mental de resonamiento de imaginación es completamente transparente para quienes dueño el computador donde corre ese proceso. Imagina una decisión de seguridad nacional. Cuyos resonamientos plano y visto por cualquier persona de un país adversario que tiene acces a esas computadoras. La única forma de evitar esto es tener datacenters nacionales propios. Los datacenters de inteligencia artificial van a ser assets nacionales fundamentales de la soberanía de un país. Un datacenter, lo que algunas personas llaman incorrectamente la nube, es un montón de computadoras, servidores que son realmente formas de aglomerar los chips conectados y amarrados a la tierra de un país y conectados a la fuente generación eléctrica de ese país. Es realmente el uso de recursos nacionales de tierra de electricidad de talento humano. Cuyos resultados deberían ser aprovechados por los humanos que viven en ese país. Y la idea de que el neershoring nos va a salvar puede ser incompatible con el realidad de joven política que estamos viviendo. El Estados Unidos de Trump ha demostrado una total voluntad de atacar países aliados sin ningún límite aparente, incluyendo la restricción de exportación de tecnologías. El crecimiento del código abierto en la inteligencia artificial es una muy buena esperanza, como lo que pasó con los modelos Lama de Meta o lo que pasó con DeepSick en China. Pero no es suficiente. No solución el problema de la acceso a los chips ni el volumen de talento humano necesario para crear el tipo de empresas capaces de montar estos sistemas en caso de que se vuelven a necesidad. China misma está varios años atrás en tecnologías como los laces litográficos, los chips avanzados y algunas técnicas especiales de AI. Esto tendrá sorprender a personas de gobierno con las que ha hablado en este proceso en los últimos seis meses. Porque, creen que si una máquina existe se puede clonar. No es la única tecnología que funciona así, por ejemplo. China lleva mucho tiempo sin éxito tratando de construir una industria de aviones que le compita a Boeing en Estados Unidos y a Airbus en Francia. No han podido. No tienen un motor jet para aviones de combate que se compare con el de la avión F-35. Y hasta ahora están empezando a aproximarse a la tecnología de absorción de radar que tiene el mundo occidental. Esto no significa que China no son países pero avanzados que aprenden muy rápido. Por supuesto que sí. Lo que significa es que ciertas tecnologías realmente están fuera alcanza de otros países. Recuerden, solo holandas capaz de fabricar laces extremos ultravioleta que hacen chips de AI. China no puede Estados Unidos, no puede Taiwan, no puede Japón, no puede etc. Era un escenario conflicto bélico de guerra, esto se vuelve mucho más importante. AI está a punto de entrar en la cadena de mando y proceso de decisiones de combate de todas las fuerzas militares del planeta. No son en la selección de objetivos o en el teatro operación, sino en todo el proceso logístico estándar. Paranéis un secreto que el software y las bases de datos de las fuerzas militares latinoamericanas están super atrasadas. Al punto de ser uno de los collos de botella más importantes de la modernización de nuestras fuerzas y lo que nos impie de integrarnos más fuerte con algunas de nuestras alianzas. Mientras en los conflictos en Ucrania e Israel el uso de AI está tan normalizado en el día a día que cambia altísima velocidad de la realidad de las guerras, incluso escribiendo muchos doctrinas que por décadas damos por centado. Imaginen un conflicto regional donde las decisiones de la cadena letal, el análisis de inteligencia o la simple logística, pasa por modelos de AI. Y ese pensamiento es transparente a los dueños de las computadoras donde corren esos modelos, lo que la gente incorrectamente llama la NUE. Y al revés, imaginen un ejército que por seguridad deciden usar estos sistemas y tomar decisiones a una velocidad hiperlenta comparado con un ejército capaz de aprovechar AI. Que nuestros países tengan programas decididos de desarrollo de talento humano que aproveche AI no es opcional. Y no es difícil necesitamos ya mismo que nuestros países sean bilíngues. La excusa de que estamos protegiendo nuestro lenguaje es eso, una excusa, holanda, logró proteger el holandés y hacer a su población bilíngue. Arrancaron por eliminar el dobleaje de inglés a holandés, como nosotros tenemos el dobleaje inglés español, en películas, en series de televisión y en todo lo que se proyectan entretenimiento. Subtítulos. Luego enfatizaron inglés en todos los niveles, desde la primaria más primaria, hasta los profesionales trabajando, pos educación que creían que no tenían que aprender de nuevo. Lo mismo tiene que pasar con los tres conceptos necesarios para entender inteligencia artificial, matrices, algeo del lineal y cálculo diferencial. Eso es todo, el resto es computación, los modelos tienen complejidad, pero no dificultad, y no están fuera de la alcance de nadie. La industria calcula que en dos años tendremos modelos inteligencia artificial más inteligentes que cualquier PhD en cualquier ruro. Dos años es más que suficiente para preparar a nuestros países. Esta puede ser una en las crisis económicas más irreversibles de nuestra historia moderna o una de las oportunidades más mágicas que ya han llegado. Estados Unidos y en particular Silicon Valley entienden muy bien esto. China entiende muy bien esto. Yo me dedico a hablar con los empresarios más grandes de nuestros países todos los días, y excepto algunos líderes muy excepcionales, la mayoría que creo que estén esparatando, que se puede comprar, que algún consultor lo traerá, fuera de China y Silicon Valley el mundo sigue dormido. Lo que viene para nuestras economías es lo que Uber fue para los taxistas, pero en una escala de todo el trabajo que depende de conocimiento y razón, no hemos excusas. No respondamos con memes o frases filosóficas vacías de que la humanidad nunca será reemplazada porque nuestro espíritu es especial o cosas por el estilo. Está bien estar en desacuerdo, está bien debatir y entender, pero no debatamos desde la emoción y el populismo. Debatamos desde entender fundamentalmente que esto es matemática simple, a la alcance de todos los que quieran aprender y cuyo oportunidad es real, así como su amenaza. La inteligencia artificial moderna es el uso masivo de microchips y matemáticas para hacerle ingeniería inversa a la mente humana a partir del lenguaje, que es la expresión máxima en escala de nuestra inteligencia y cultura. Y está funcionando. Despertemos.\n"
          ]
        }
      ]
    }
  ]
}